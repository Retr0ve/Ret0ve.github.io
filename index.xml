<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Retr0ve&#39;s Veil Cave</title>
    <link>http://Retr0ve.github.io/</link>
    <description>Recent content on Retr0ve&#39;s Veil Cave</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Feb 2021 20:03:14 +0800</lastBuildDate><atom:link href="http://Retr0ve.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hello World!</title>
      <link>http://Retr0ve.github.io/posts/new-to-hugo/new-to-hugo/</link>
      <pubDate>Sun, 28 Feb 2021 20:03:14 +0800</pubDate>
      
      <guid>http://Retr0ve.github.io/posts/new-to-hugo/new-to-hugo/</guid>
      <description>从Wordpress到Gridea再到最后的Hugo，这个个人博客总算是有了它最终的归宿。作为一名程序员，新博客的第一篇就简单的总结以下Hugo的搭建流程，以及静态博客生成器相较于动态博客的优点。
搭建一个静态博客 静态博客的搭建由于不需要数据库等服务端的配置，相较于动态博客来说简单不少，仅仅需要将生成器的环境在本地搭建好，再准备好博客的内容就万事大吉了。下面我将用Hugo + GitHub Pages进行举例。
01 开始！ 万事开头难，然而开头也不难，第一步需要下载Hugo最新的release。
 前往https://github.com/gohugoio/hugo/releases下载最新的Hugo Release。对于MacOS、Linux来说可以直接使用homebrew等工具直接安装，安装过程和windows略有不同，具体请参考官方文档https://gohugo.io/getting-started/quick-start/。 解压后打开命令行终端，进入安装目录。 输入hugo.exe version查看是否能正常启动。（此处可以将Hugo添加到环境变量，便于后续指令的输入。为了书写上简化，后续用hugo代替hugo可执行文件的路径。）  此时如果能够正常显示版本，说明你的Hugo在本地已经安装好了。
02 准备GitHub Page仓库 相比动态博客需要单独租用VPS或者服务器来说，静态博客在经济上更让人省心。由于不需要后台，我们可以直接将博客托管在GitHub Page、Dropbox等存储服务提供商上。这里我们用GitHub进行演示：
  新建一个名为[你的GitHub用户名].github.io的仓库
  进入仓库的setting
  将下方的Source更改为/docs
  至此你的GitHub Pages也配置好了。
03 建站   输入hugo new site [你的站点名字]创建一个新的站点。
  进入你刚刚创建的站点cd [你的站点名字]
  在https://themes.gohugo.io/中找到你喜欢的主题并clone下来（如果此处不想使用git的话，也可以通过GitHub的Download to Desktop下载压缩包）
  将clone下来的主题复制到theme目录（解压该 .zip 文件到你的博客主题 theme 目录）
  重命名 hugo-[主题名]-master 为 [主题名]
  将theme = &amp;quot;[主题名]&amp;quot;添加至根目录下的config.toml，再顺手配置一下站点的相关信息。配置完成后看起来应该是这样的（由于本人不习惯toml的语法，因此改为了yml，Hugo支持使用toml、yml以及json作为配置文件）：</description>
    </item>
    
    <item>
      <title>数据挖掘[2] - 主成分分析&amp;非负矩阵分解</title>
      <link>http://Retr0ve.github.io/posts/shu-ju-wa-jue-2-zhu-cheng-fen-fen-xi-andfei-fu-ju-zhen-fen-jie/</link>
      <pubDate>Sun, 28 Feb 2021 20:03:14 +0800</pubDate>
      
      <guid>http://Retr0ve.github.io/posts/shu-ju-wa-jue-2-zhu-cheng-fen-fen-xi-andfei-fu-ju-zhen-fen-jie/</guid>
      <description>1 总体作用 简单来说，主成分分析和非负矩阵分解起到对数据降维、压缩并提取特征的作用。在收集数据时，人们通常倾向于全面的收集各维度的数据。一方面更多维度的数据可以更好的描述个体，但另一方面在对对象进行分析时通常高维度不利于对数据的解读。 例如描述高考成绩时，通常会有六门考试，这六门考试的成绩能够很好的反应个体的学习状况。然而，在进行分析的时候，我们通常会将理科归类在一起称之为理综（文综同理），这就是降维的思想。
2 主成分分析 （Principal Components Analysis） Karl Pearson ，数理统计学创立者首先提出了主成分分析的思想。
 代数观点：变量替换，使得协方差阵对角化（变量正交） 几何观点：寻找正交坐标系，使之指向样本点散布最开的方向 作用：降低数据集维数，保持数据特征  2.1 基本原理  将原来变量（特征）重新组合成相互无关的综合变量，保留少量综合变量而尽可能多地保留信息。 数学上，将原来变量的线性组合作为新的综合变量，用方差来表达信息量。 线性组合中方差最大的作第一主成分，以此类推，直到信息保留足够多。   2.2 基本过程  数据标准化  中心化：列减均值 归一化：列除以标准差（消除尺度差异） 得到标准化后的$X$矩阵   计算协方差矩阵  矩阵$X$乘以其转置 $R=X&amp;rsquo;X$   求特征值和特征向量  求解特征方程 行列式=0 。。。 特征向量即为主成分   分解到主成分  取前q个主成分使得 阿尔法为保留的信息量（保留95%即0.95） 第i个样本在第j个主成分上的投影 在q个主成分上的投影向量（在新坐标系下的坐标） 所有样本分解 XV    2.3 应用场景  发掘样本间隐藏的联系 通过多维度描述个体，最后对个体进行评价时通过主成分分析可提现 去除样本中冗余的属性和噪声 去除贡献少的成分 数据降维从而可视化 人只适应二维和三维的图表，对于高维数据要进行可视化必须进行数据降维。 减少数据、加速机器学习过程 筛选回归变量、构造回归模型  2.</description>
    </item>
    
    <item>
      <title>数据挖掘[2] - 主成分分析&amp;非负矩阵分解</title>
      <link>http://Retr0ve.github.io/shu-ju-wa-jue-2-zhu-cheng-fen-fen-xi-andfei-fu-ju-zhen-fen-jie/</link>
      <pubDate>Sat, 30 Jan 2021 01:04:34 +0000</pubDate>
      
      <guid>http://Retr0ve.github.io/shu-ju-wa-jue-2-zhu-cheng-fen-fen-xi-andfei-fu-ju-zhen-fen-jie/</guid>
      <description>1 总体作用 简单来说，主成分分析和非负矩阵分解起到对数据降维、压缩并提取特征的作用。在收集数据时，人们通常倾向于全面的收集各维度的数据。一方面更多维度的数据可以更好的描述个体，但另一方面在对对象进行分析时通常高维度不利于对数据的解读。 例如描述高考成绩时，通常会有六门考试，这六门考试的成绩能够很好的反应个体的学习状况。然而，在进行分析的时候，我们通常会将理科归类在一起称之为理综（文综同理），这就是降维的思想。
2 主成分分析 （Principal Components Analysis） Karl Pearson ，数理统计学创立者首先提出了主成分分析的思想。
 代数观点：变量替换，使得协方差阵对角化（变量正交） 几何观点：寻找正交坐标系，使之指向样本点散布最开的方向 作用：降低数据集维数，保持数据特征  2.1 基本原理  将原来变量（特征）重新组合成相互无关的综合变量，保留少量综合变量而尽可能多地保留信息。 数学上，将原来变量的线性组合作为新的综合变量，用方差来表达信息量。 线性组合中方差最大的作第一主成分，以此类推，直到信息保留足够多。   2.2 基本过程  数据标准化  中心化：列减均值 归一化：列除以标准差（消除尺度差异） 得到标准化后的$X$矩阵   计算协方差矩阵  矩阵$X$乘以其转置 $R=X&amp;rsquo;X$   求特征值和特征向量  求解特征方程 行列式=0 。。。 特征向量即为主成分   分解到主成分  取前q个主成分使得 阿尔法为保留的信息量（保留95%即0.95） 第i个样本在第j个主成分上的投影 在q个主成分上的投影向量（在新坐标系下的坐标） 所有样本分解 XV    2.3 应用场景  发掘样本间隐藏的联系 通过多维度描述个体，最后对个体进行评价时通过主成分分析可提现 去除样本中冗余的属性和噪声 去除贡献少的成分 数据降维从而可视化 人只适应二维和三维的图表，对于高维数据要进行可视化必须进行数据降维。 减少数据、加速机器学习过程 筛选回归变量、构造回归模型  2.</description>
    </item>
    
    <item>
      <title>数据挖掘[1] - 数据清洗</title>
      <link>http://Retr0ve.github.io/data-mining-1-data-cleaning/</link>
      <pubDate>Fri, 29 Jan 2021 05:51:34 +0000</pubDate>
      
      <guid>http://Retr0ve.github.io/data-mining-1-data-cleaning/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
